# Lecture 8 -- Boosting method (XGBoost)

+++
---

**Here, we will mainly talk about the different Boosting methods used for tree models, such as Adaboost, and xGboost, etc.**



<span style = "color: red; font-weight: 500;  font-size: 30px; text-align: left">Contents of this lecture</span>  <br />

* Background (basic formulation of regression)
* Ensemble decision trees for regression
   >- Random forest
   >- Bagging
   >- Boosting
* Gradient boosting
* eXtreme Gradient Boosting (XGBoost)
* Summary





```{figure} ./lectures/lecture8.png
---
height: 1600px
name: lecture8
---
```
```{figure} ./lectures/lecture8-1.png
---
height: 1600px
name: lecture8-1
---
```
```{figure} ./lectures/lecture8-2.png
---
height: 1600px
name: lecture8-2
---
```



**Please download the lecture through the following link [Lecture 8 -- Boosting method (XGBoost)](https://github.com/wengangmao/fmms050/blob/main/contents/machine-learning/lectures/Lecture%208%20-%20ML2%20Trains_XGboost_examples.pdf)**