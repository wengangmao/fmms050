

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lecture 5: Excercise &#8212; ML for engineering mechanics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'contents/regression/tutorials/lecture5/excercise';</script>
    <link rel="shortcut icon" href="../../../../_static/learning.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Logistical regression and classification" href="../../../machine-learning/logistic.html" />
    <link rel="prev" title="Lecture 5: Examples of GLM and GAM" href="examples.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../introduction.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/learning.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../../_static/learning.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../introduction.html">
                    FMMS050 - Statistical regression and machine learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">PART 1 -- MACHINE LEARNING FOR ENGINEERING APPLICATIONS</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../ml-engineering/intro_applications.html">Lecture 1 -- AI/ML terminologies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-engineering/ml-types.html">Types of machine learning methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-engineering/basic-math.html">Basic mathematics for machine learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PART 2 -- STATISTICAL REGRESSION</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../lecture2-interperations.html">Lecture 2 -- Regression and interpretation</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../lecture2/examples.html">Computer Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture2/excercise.html">Computer Excercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../lecture3-poly-spline.html">Lecture 3 -- Polynominal and spline fitting</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../lecture3/examples.html"><strong>Demonstration of examples for Lecure 3:</strong></a></li>


</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../lecture4-reg-gradient.html">Lecture 4 -- Model parameter estimation - gradient</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../lecture4/examples.html"><strong>Demonstration example for Lecture 4: Gradient method for parameter estimation</strong></a></li>

<li class="toctree-l2"><a class="reference internal" href="../lecture4/excercise.html">Computer Excercises</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../lecture5-gam-mem.html">Lecture 5 - GLM GAM and Mixed-effects model</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="examples.html">Computer Examples</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#"><strong>Lecture 5: Excercise</strong></a></li>

</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PART 3 -- MACHINE LEARNING METHODS</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../machine-learning/logistic.html">Logistical regression and classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../machine-learning/ann.html">Artificial neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../machine-learning/svm.html">Support vector machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../machine-learning/trees.html">Decision trees and ensemble algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../machine-learning/boost.html">Boosting methods (XGBoost)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PART 4 -- TIME SERIES LEARNING METHODS</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../time-series/gaussian-transform.html">Gaussian transformation methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../time-series/stationary-gaussian.html">Basic properties of stationary Gaussian process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../time-series/acf.html">Autocorrelation and Conditional expectation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../time-series/ar-ma.html">Auto regressive models and Moving average models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../time-series/arima.html">ARIMA models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PROJECT ASSIGNMENT</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../assignment/project1.html">Project 1 -- Simple regression for roll damping</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://wengangmao.github.io/fmms050/hub/user-redirect/git-pull?repo=https%3A//github.com/wengangmao/fmms050&urlpath=tree/fmms050/./contents/regression/tutorials/lecture5/excercise.ipynb&branch=master" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onJupyterHub"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../_static/images/logo_jupyterhub.svg">
  </span>
<span class="btn__text-container">JupyterHub</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/wengangmao/fmms050" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/wengangmao/fmms050/edit/master/./contents/regression/tutorials/lecture5/excercise.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/wengangmao/fmms050/issues/new?title=Issue%20on%20page%20%2Fcontents/regression/tutorials/lecture5/excercise.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/contents/regression/tutorials/lecture5/excercise.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 5: Excercise</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Lecture 5: Excercise</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#tweedie-regression-on-insurance-claims">Tweedie regression on insurance claims</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-datasets-basic-feature-extraction-and-target-definitions">Loading datasets, basic feature extraction and target definitions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frequency-model-poisson-distribution">Frequency model – Poisson distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#severity-model-gamma-distribution">Severity Model -  Gamma distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor">Pure Premium Modeling via a Product Model vs single TweedieRegressor</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-5-excercise">
<h1><strong>Lecture 5: Excercise</strong><a class="headerlink" href="#lecture-5-excercise" title="Permalink to this heading">#</a></h1>
<p>This code is directly copied from scikit website. Your tasks for this excercise is:</p>
<ul class="simple">
<li><p>1, Run the code and understand it</p></li>
<li><p>2, Write a brief summary of this project</p></li>
</ul>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="tweedie-regression-on-insurance-claims">
<h1>Tweedie regression on insurance claims<a class="headerlink" href="#tweedie-regression-on-insurance-claims" title="Permalink to this heading">#</a></h1>
<p>This example illustrates the use of Poisson, Gamma and Tweedie regression on
the <a class="reference external" href="https://www.openml.org/d/41214">French Motor Third-Party Liability Claims dataset</a>, and is inspired by an R tutorial [1]_.</p>
<p>In this dataset, each sample corresponds to an insurance policy, i.e. a
contract within an insurance company and an individual (policyholder).
Available features include driver age, vehicle age, vehicle power, etc.</p>
<p>A few definitions: a <em>claim</em> is the request made by a policyholder to the
insurer to compensate for a loss covered by the insurance. The <em>claim amount</em>
is the amount of money that the insurer must pay. The <em>exposure</em> is the
duration of the insurance coverage of a given policy, in years.</p>
<p>Here our goal is to predict the expected
value, i.e. the mean, of the total claim amount per exposure unit also
referred to as the pure premium.</p>
<p>There are several possibilities to do that, two of which are:</p>
<ol class="arabic simple">
<li><p>Model the number of claims with a Poisson distribution, and the average
claim amount per claim, also known as severity, as a Gamma distribution
and multiply the predictions of both in order to get the total claim
amount.</p></li>
<li><p>Model the total claim amount per exposure directly, typically with a Tweedie
distribution of Tweedie power <span class="math notranslate nohighlight">\(p \in (1, 2)\)</span>.</p></li>
</ol>
<p>In this example we will illustrate both approaches. We start by defining a few
helper functions for loading the data and visualizing results.</p>
<p>.. [1]  A. Noll, R. Salzmann and M.V. Wuthrich, Case Study: French Motor
Third-Party Liability Claims (November 8, 2018). <a class="reference external" href="http://dx.doi.org/10.2139/ssrn.3164764">doi:10.2139/ssrn.3164764</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Christian Lorentzen &lt;lorentzen.ch@gmail.com&gt;</span>
<span class="c1">#          Roman Yurchak &lt;rth.yurchak@gmail.com&gt;</span>
<span class="c1">#          Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1"># License: BSD 3 clause</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_tweedie_deviance</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>


<span class="k">def</span> <span class="nf">load_mtpl2</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fetch the French Motor Third-Party Liability Claims dataset.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_samples: int, default=None</span>
<span class="sd">      number of samples to select (for faster run time). Full dataset has</span>
<span class="sd">      678013 samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># freMTPL2freq dataset from https://www.openml.org/d/41214</span>
    <span class="n">df_freq</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="mi">41214</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parser</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
    <span class="n">df_freq</span><span class="p">[</span><span class="s2">&quot;IDpol&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_freq</span><span class="p">[</span><span class="s2">&quot;IDpol&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">df_freq</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;IDpol&quot;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># freMTPL2sev dataset from https://www.openml.org/d/41215</span>
    <span class="n">df_sev</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">data_id</span><span class="o">=</span><span class="mi">41215</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parser</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>

    <span class="c1"># sum ClaimAmount over identical IDs</span>
    <span class="n">df_sev</span> <span class="o">=</span> <span class="n">df_sev</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;IDpol&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">df_freq</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_sev</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># unquote string fields</span>
    <span class="k">for</span> <span class="n">column_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="nb">object</span><span class="p">]:</span>
        <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span>
    <span class="n">feature</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">,</span>
    <span class="n">observed</span><span class="p">,</span>
    <span class="n">predicted</span><span class="p">,</span>
    <span class="n">y_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot observed and predicted - aggregated per feature level.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    df : DataFrame</span>
<span class="sd">        input data</span>
<span class="sd">    feature: str</span>
<span class="sd">        a column name of df for the feature to be plotted</span>
<span class="sd">    weight : str</span>
<span class="sd">        column name of df with the values of weights or exposure</span>
<span class="sd">    observed : str</span>
<span class="sd">        a column name of df with the observed target</span>
<span class="sd">    predicted : DataFrame</span>
<span class="sd">        a dataframe, with the same index as df, with the predicted target</span>
<span class="sd">    fill_legend : bool, default=False</span>
<span class="sd">        whether to show fill_between legend</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># aggregate observed and predicted variables by feature level</span>
    <span class="n">df_</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">feature</span><span class="p">,</span> <span class="n">weight</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">df_</span><span class="p">[</span><span class="s2">&quot;observed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">observed</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span>
    <span class="n">df_</span><span class="p">[</span><span class="s2">&quot;predicted&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span>
    <span class="n">df_</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df_</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">feature</span><span class="p">])[[</span><span class="n">weight</span><span class="p">,</span> <span class="s2">&quot;observed&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted&quot;</span><span class="p">]]</span>
        <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">observed</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;observed&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">x</span><span class="p">[</span><span class="n">weight</span><span class="p">])</span>
        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">predicted</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;predicted&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">x</span><span class="p">[</span><span class="n">weight</span><span class="p">])</span>
    <span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">df_</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;observed&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">y_max</span> <span class="o">=</span> <span class="n">df_</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;observed&quot;</span><span class="p">,</span> <span class="s2">&quot;predicted&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.8</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">df_</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="n">y_max</span> <span class="o">*</span> <span class="n">df_</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span> <span class="o">/</span> <span class="n">df_</span><span class="p">[</span><span class="n">weight</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">fill_legend</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> distribution&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">)])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">y_label</span> <span class="k">if</span> <span class="n">y_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="n">title</span> <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;Train: Observed vs Predicted&quot;</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">score_estimator</span><span class="p">(</span>
    <span class="n">estimator</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluate an estimator on train and test sets with different metrics&quot;&quot;&quot;</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;D² explained&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>  <span class="c1"># Use default scorer if it exists</span>
        <span class="p">(</span><span class="s2">&quot;mean abs. error&quot;</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;mean squared error&quot;</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">),</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">tweedie_powers</span><span class="p">:</span>
        <span class="n">metrics</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">(</span>
                <span class="s2">&quot;mean Tweedie dev p=</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">power</span><span class="p">),</span>
                <span class="n">partial</span><span class="p">(</span><span class="n">mean_tweedie_deviance</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="n">power</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">power</span> <span class="ow">in</span> <span class="n">tweedie_powers</span>
        <span class="p">]</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">subset_label</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">df_test</span><span class="p">),</span>
    <span class="p">]:</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">_weights</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">score_label</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Score the model consisting of the product of frequency and</span>
                <span class="c1"># severity models.</span>
                <span class="n">est_freq</span><span class="p">,</span> <span class="n">est_sev</span> <span class="o">=</span> <span class="n">estimator</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">est_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">est_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">_weights</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">score</span> <span class="o">=</span> <span class="n">metric</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">_weights</span><span class="p">)</span>

            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;subset&quot;</span><span class="p">:</span> <span class="n">subset_label</span><span class="p">,</span> <span class="s2">&quot;metric&quot;</span><span class="p">:</span> <span class="n">score_label</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">})</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
        <span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;metric&quot;</span><span class="p">,</span> <span class="s2">&quot;subset&quot;</span><span class="p">])</span>
        <span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div>
</div>
<section id="loading-datasets-basic-feature-extraction-and-target-definitions">
<h2>Loading datasets, basic feature extraction and target definitions<a class="headerlink" href="#loading-datasets-basic-feature-extraction-and-target-definitions" title="Permalink to this heading">#</a></h2>
<p>We construct the freMTPL2 dataset by joining the freMTPL2freq table,
containing the number of claims (<code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code>), with the freMTPL2sev table,
containing the claim amount (<code class="docutils literal notranslate"><span class="pre">ClaimAmount</span></code>) for the same policy ids
(<code class="docutils literal notranslate"><span class="pre">IDpol</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">KBinsDiscretizer</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">load_mtpl2</span><span class="p">()</span>

<span class="c1"># Note: filter out claims with zero amount, as the severity model</span>
<span class="c1"># requires strictly positive target values.</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Correct for unreasonable observations (that might be data error)</span>
<span class="c1"># and a few exceptionally large claim amounts</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">upper</span><span class="o">=</span><span class="mi">200000</span><span class="p">)</span>

<span class="n">log_scale_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">),</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">column_trans</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span>
            <span class="s2">&quot;binned_numeric&quot;</span><span class="p">,</span>
            <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">2e5</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="p">[</span><span class="s2">&quot;VehAge&quot;</span><span class="p">,</span> <span class="s2">&quot;DrivAge&quot;</span><span class="p">],</span>
        <span class="p">),</span>
        <span class="p">(</span>
            <span class="s2">&quot;onehot_categorical&quot;</span><span class="p">,</span>
            <span class="n">OneHotEncoder</span><span class="p">(),</span>
            <span class="p">[</span><span class="s2">&quot;VehBrand&quot;</span><span class="p">,</span> <span class="s2">&quot;VehPower&quot;</span><span class="p">,</span> <span class="s2">&quot;VehGas&quot;</span><span class="p">,</span> <span class="s2">&quot;Region&quot;</span><span class="p">,</span> <span class="s2">&quot;Area&quot;</span><span class="p">],</span>
        <span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;passthrough_numeric&quot;</span><span class="p">,</span> <span class="s2">&quot;passthrough&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;BonusMalus&quot;</span><span class="p">]),</span>
        <span class="p">(</span><span class="s2">&quot;log_scaled_numeric&quot;</span><span class="p">,</span> <span class="n">log_scale_transformer</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Density&quot;</span><span class="p">]),</span>
    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><span class="s2">&quot;drop&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">column_trans</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Insurances companies are interested in modeling the Pure Premium, that is</span>
<span class="c1"># the expected total claim amount per unit of exposure for each policyholder</span>
<span class="c1"># in their portfolio:</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span>

<span class="c1"># This can be indirectly approximated by a 2-step modeling: the product of the</span>
<span class="c1"># Frequency times the average claim amount per claim:</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Frequency&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">fmax</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pd</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span><span class="s2">&quot;display.max_columns&quot;</span><span class="p">,</span> <span class="mi">15</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">ClaimAmount</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       ClaimNb  Exposure Area  VehPower  VehAge  DrivAge  BonusMalus VehBrand  \
IDpol                                                                           
139          1      0.75    F         7       1       61          50      B12   
190          1      0.14    B        12       5       50          60      B12   
414          1      0.14    E         4       0       36          85      B12   
424          2      0.62    F        10       0       51         100      B12   
463          1      0.31    A         5       0       45          50      B12   

        VehGas  Density Region  ClaimAmount   PurePremium  Frequency  \
IDpol                                                                  
139    Regular    27000    R11       303.00    404.000000   1.333333   
190     Diesel       56    R25      1981.84  14156.000000   7.142857   
414    Regular     4792    R11      1456.55  10403.928571   7.142857   
424    Regular    27000    R11     10834.00  17474.193548   3.225806   
463    Regular       12    R73      3986.67  12860.225806   3.225806   

       AvgClaimAmount  
IDpol                  
139            303.00  
190           1981.84  
414           1456.55  
424           5417.00  
463           3986.67  
</pre></div>
</div>
</div>
</div>
</section>
<section id="frequency-model-poisson-distribution">
<h2>Frequency model – Poisson distribution<a class="headerlink" href="#frequency-model-poisson-distribution" title="Permalink to this heading">#</a></h2>
<p>The number of claims (<code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code>) is a positive integer (0 included).
Thus, this target can be modelled by a Poisson distribution.
It is then assumed to be the number of discrete events occurring with a
constant rate in a given time interval (<code class="docutils literal notranslate"><span class="pre">Exposure</span></code>, in units of years).
Here we model the frequency <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">ClaimNb</span> <span class="pre">/</span> <span class="pre">Exposure</span></code>, which is still a
(scaled) Poisson distribution, and use <code class="docutils literal notranslate"><span class="pre">Exposure</span></code> as <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">PoissonRegressor</span>


<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us keep in mind that despite the seemingly large number of data points in
this dataset, the number of evaluation points where the claim amount is
non-zero is quite small:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>169504
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>6237
</pre></div>
</div>
</div>
</div>
<p>As a consequence, we expect a significant variability in our
evaluation upon random resampling of the train test split.</p>
<p>The parameters of the model are estimated by minimizing the Poisson deviance
on the training set via a Newton solver. Some of the features are collinear
(e.g. because we did not drop any categorical level in the <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code>),
we use a weak L2 penalization to avoid numerical issues.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">glm_freq</span> <span class="o">=</span> <span class="n">PoissonRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;newton-cholesky&quot;</span><span class="p">)</span>
<span class="n">glm_freq</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;Frequency&quot;</span><span class="p">],</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">])</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_freq</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluation of PoissonRegressor on target Frequency&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Evaluation of PoissonRegressor on target Frequency
subset               train    test
metric                            
D² explained        0.0201  0.0219
mean abs. error     0.1379  0.1378
mean squared error  0.2441  0.2246
</pre></div>
</div>
</div>
</div>
<p>Note that the score measured on the test set is surprisingly better than on
the training set. This might be specific to this random train-test split.
Proper cross-validation could help us to assess the sampling variability of
these results.</p>
<p>We can visually compare observed and predicted values, aggregated by the
drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>), vehicle age (<code class="docutils literal notranslate"><span class="pre">VehAge</span></code>) and the insurance
bonus/malus (<code class="docutils literal notranslate"><span class="pre">BonusMalus</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_train</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;DrivAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Claim Frequency&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;train data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;DrivAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Claim Frequency&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;test data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;VehAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Claim Frequency&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;test data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;BonusMalus&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Claim Frequency&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;test data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/eddabe6b84438c23536037fb391e2cfa8ba8706ee278453cac3553d3130c2c18.png" src="../../../../_images/eddabe6b84438c23536037fb391e2cfa8ba8706ee278453cac3553d3130c2c18.png" />
</div>
</div>
<p>According to the observed data, the frequency of accidents is higher for
drivers younger than 30 years old, and is positively correlated with the
<code class="docutils literal notranslate"><span class="pre">BonusMalus</span></code> variable. Our model is able to mostly correctly model this
behaviour.</p>
</section>
<section id="severity-model-gamma-distribution">
<h2>Severity Model -  Gamma distribution<a class="headerlink" href="#severity-model-gamma-distribution" title="Permalink to this heading">#</a></h2>
<p>The mean claim amount or severity (<code class="docutils literal notranslate"><span class="pre">AvgClaimAmount</span></code>) can be empirically
shown to follow approximately a Gamma distribution. We fit a GLM model for
the severity with the same features as the frequency model.</p>
<p>Note:</p>
<ul class="simple">
<li><p>We filter out <code class="docutils literal notranslate"><span class="pre">ClaimAmount</span> <span class="pre">==</span> <span class="pre">0</span></code> as the Gamma distribution has support
on <span class="math notranslate nohighlight">\((0, \infty)\)</span>, not <span class="math notranslate nohighlight">\([0, \infty)\)</span>.</p></li>
<li><p>We use <code class="docutils literal notranslate"><span class="pre">ClaimNb</span></code> as <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> to account for policies that contain
more than one claim.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">GammaRegressor</span>


<span class="n">mask_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">mask_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>

<span class="n">glm_sev</span> <span class="o">=</span> <span class="n">GammaRegressor</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;newton-cholesky&quot;</span><span class="p">)</span>

<span class="n">glm_sev</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">],</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">&quot;ClaimNb&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_sev</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">X_test</span><span class="p">[</span><span class="n">mask_test</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="p">[</span><span class="n">mask_train</span><span class="p">],</span>
    <span class="n">df_test</span><span class="p">[</span><span class="n">mask_test</span><span class="p">],</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluation of GammaRegressor on target AvgClaimAmount&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Evaluation of GammaRegressor on target AvgClaimAmount
subset                     train          test
metric                                        
D² explained        2.400000e-03  2.700000e-03
mean abs. error     1.756746e+03  1.744042e+03
mean squared error  5.801770e+07  5.030677e+07
</pre></div>
</div>
</div>
</div>
<p>Those values of the metrics are not necessarily easy to interpret. It can be
insightful to compare them with a model that does not use any input
features and always predicts a constant value, i.e. the average claim
amount, in the same setting:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyRegressor</span>

<span class="n">dummy_sev</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="n">dummy_sev</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">],</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">,</span> <span class="s2">&quot;ClaimNb&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">dummy_sev</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">X_test</span><span class="p">[</span><span class="n">mask_test</span><span class="o">.</span><span class="n">values</span><span class="p">],</span>
    <span class="n">df_train</span><span class="p">[</span><span class="n">mask_train</span><span class="p">],</span>
    <span class="n">df_test</span><span class="p">[</span><span class="n">mask_test</span><span class="p">],</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;ClaimNb&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluation of a mean predictor on target AvgClaimAmount&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Evaluation of a mean predictor on target AvgClaimAmount
subset                     train          test
metric                                        
D² explained        0.000000e+00 -0.000000e+00
mean abs. error     1.756687e+03  1.744497e+03
mean squared error  5.803882e+07  5.033764e+07
</pre></div>
</div>
</div>
</div>
<p>We conclude that the claim amount is very challenging to predict. Still, the
:class:<code class="docutils literal notranslate"><span class="pre">~sklearn.linear.GammaRegressor</span></code> is able to leverage some information
from the input features to slighly improve upon the mean baseline in terms
of D².</p>
<p>Note that the resulting model is the average claim amount per claim. As such,
it is conditional on having at least one claim, and cannot be used to predict
the average claim amount per policy. For this, it needs to be combined with
a claims frequency model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean AvgClaim Amount per policy:              </span><span class="si">%.2f</span><span class="s2"> &quot;</span>
    <span class="o">%</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean AvgClaim Amount | NbClaim &gt; 0:           </span><span class="si">%.2f</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">][</span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Predicted Mean AvgClaim Amount | NbClaim &gt; 0: </span><span class="si">%.2f</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Predicted Mean AvgClaim Amount (dummy) | NbClaim &gt; 0: </span><span class="si">%.2f</span><span class="s2">&quot;</span>
    <span class="o">%</span> <span class="n">dummy_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean AvgClaim Amount per policy:              71.78 
Mean AvgClaim Amount | NbClaim &gt; 0:           1951.21
Predicted Mean AvgClaim Amount | NbClaim &gt; 0: 1940.95
Predicted Mean AvgClaim Amount (dummy) | NbClaim &gt; 0: 1978.59
</pre></div>
</div>
</div>
</div>
<p>We can visually compare observed and predicted values, aggregated for
the drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_train</span><span class="p">],</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;DrivAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">mask_train</span><span class="o">.</span><span class="n">values</span><span class="p">]),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Average Claim Severity&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;train data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">plot_obs_pred</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df_test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_test</span><span class="p">],</span>
    <span class="n">feature</span><span class="o">=</span><span class="s2">&quot;DrivAge&quot;</span><span class="p">,</span>
    <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="s2">&quot;AvgClaimAmount&quot;</span><span class="p">,</span>
    <span class="n">predicted</span><span class="o">=</span><span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">mask_test</span><span class="o">.</span><span class="n">values</span><span class="p">]),</span>
    <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;Average Claim Severity&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;test data&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">fill_legend</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/7e075e410eb1f3d9f8755cbb8f962ab855db5dbdc68cb58137bc26d9a68232b6.png" src="../../../../_images/7e075e410eb1f3d9f8755cbb8f962ab855db5dbdc68cb58137bc26d9a68232b6.png" />
</div>
</div>
<p>Overall, the drivers age (<code class="docutils literal notranslate"><span class="pre">DrivAge</span></code>) has a weak impact on the claim
severity, both in observed and predicted data.</p>
</section>
<section id="pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor">
<h2>Pure Premium Modeling via a Product Model vs single TweedieRegressor<a class="headerlink" href="#pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor" title="Permalink to this heading">#</a></h2>
<p>As mentioned in the introduction, the total claim amount per unit of
exposure can be modeled as the product of the prediction of the
frequency model by the prediction of the severity model.</p>
<p>Alternatively, one can directly model the total loss with a unique
Compound Poisson Gamma generalized linear model (with a log link function).
This model is a special case of the Tweedie GLM with a “power” parameter
<span class="math notranslate nohighlight">\(p \in (1, 2)\)</span>. Here, we fix apriori the <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter of the
Tweedie model to some arbitrary value (1.9) in the valid range. Ideally one
would select this value via grid-search by minimizing the negative
log-likelihood of the Tweedie model, but unfortunately the current
implementation does not allow for this (yet).</p>
<p>We will compare the performance of both approaches.
To quantify the performance of both models, one can compute
the mean deviance of the train and test data assuming a Compound
Poisson-Gamma distribution of the total claim amount. This is equivalent to
a Tweedie distribution with a <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter between 1 and 2.</p>
<p>The :func:<code class="docutils literal notranslate"><span class="pre">sklearn.metrics.mean_tweedie_deviance</span></code> depends on a <code class="docutils literal notranslate"><span class="pre">power</span></code>
parameter. As we do not know the true value of the <code class="docutils literal notranslate"><span class="pre">power</span></code> parameter, we here
compute the mean deviances for a grid of possible values, and compare the
models side by side, i.e. we compare them at identical values of <code class="docutils literal notranslate"><span class="pre">power</span></code>.
Ideally, we hope that one model will be consistently better than the other,
regardless of <code class="docutils literal notranslate"><span class="pre">power</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">TweedieRegressor</span>


<span class="n">glm_pure_premium</span> <span class="o">=</span> <span class="n">TweedieRegressor</span><span class="p">(</span><span class="n">power</span><span class="o">=</span><span class="mf">1.9</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;newton-cholesky&quot;</span><span class="p">)</span>
<span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">],</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">tweedie_powers</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="mf">1.99</span><span class="p">,</span> <span class="mf">1.999</span><span class="p">,</span> <span class="mf">1.9999</span><span class="p">]</span>

<span class="n">scores_product_model</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="p">(</span><span class="n">glm_freq</span><span class="p">,</span> <span class="n">glm_sev</span><span class="p">),</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="n">tweedie_powers</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">scores_glm_pure_premium</span> <span class="o">=</span> <span class="n">score_estimator</span><span class="p">(</span>
    <span class="n">glm_pure_premium</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">df_train</span><span class="p">,</span>
    <span class="n">df_test</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;Exposure&quot;</span><span class="p">,</span>
    <span class="n">tweedie_powers</span><span class="o">=</span><span class="n">tweedie_powers</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
    <span class="p">[</span><span class="n">scores_product_model</span><span class="p">,</span> <span class="n">scores_glm_pure_premium</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sort</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Product Model&quot;</span><span class="p">,</span> <span class="s2">&quot;TweedieRegressor&quot;</span><span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluation of the Product Model and the Tweedie Regressor on target PurePremium&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">pd</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span><span class="s2">&quot;display.expand_frame_repr&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Evaluation of the Product Model and the Tweedie Regressor on target PurePremium
                          Product Model               TweedieRegressor              
subset                            train          test            train          test
metric                                                                              
D² explained                        NaN           NaN     1.690000e-02  1.420000e-02
mean Tweedie dev p=1.5000  7.669930e+01  7.617050e+01     7.640770e+01  7.640880e+01
mean Tweedie dev p=1.7000  3.695740e+01  3.683980e+01     3.682880e+01  3.692270e+01
mean Tweedie dev p=1.8000  3.046010e+01  3.040530e+01     3.037600e+01  3.045390e+01
mean Tweedie dev p=1.9000  3.387580e+01  3.385000e+01     3.382120e+01  3.387830e+01
mean Tweedie dev p=1.9900  2.015716e+02  2.015414e+02     2.015347e+02  2.015587e+02
mean Tweedie dev p=1.9990  1.914573e+03  1.914370e+03     1.914538e+03  1.914387e+03
mean Tweedie dev p=1.9999  1.904751e+04  1.904556e+04     1.904747e+04  1.904558e+04
mean abs. error            2.730119e+02  2.722128e+02     2.739865e+02  2.731249e+02
mean squared error         3.295040e+07  3.212197e+07     3.295505e+07  3.213056e+07
</pre></div>
</div>
</div>
</div>
<p>In this example, both modeling approaches yield comparable performance
metrics. For implementation reasons, the percentage of explained variance
<span class="math notranslate nohighlight">\(D^2\)</span> is not available for the product model.</p>
<p>We can additionally validate these models by comparing observed and
predicted total claim amount over the test and train subsets. We see that,
on average, both model tend to underestimate the total claim (but this
behavior depends on the amount of regularization).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">subset_label</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">df_train</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">df_test</span><span class="p">),</span>
<span class="p">]:</span>
    <span class="n">exposure</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;subset&quot;</span><span class="p">:</span> <span class="n">subset_label</span><span class="p">,</span>
            <span class="s2">&quot;observed&quot;</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;ClaimAmount&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
            <span class="s2">&quot;predicted, frequency*severity model&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">exposure</span> <span class="o">*</span> <span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="s2">&quot;predicted, tweedie, power=</span><span class="si">%.2f</span><span class="s2">&quot;</span>
            <span class="o">%</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">power</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exposure</span> <span class="o">*</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;subset&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>subset                                      train          test
observed                             3.917618e+07  1.299546e+07
predicted, frequency*severity model  3.916555e+07  1.313276e+07
predicted, tweedie, power=1.90       3.951751e+07  1.325198e+07
</pre></div>
</div>
</div>
</div>
<p>Finally, we can compare the two models using a plot of cumulated claims: for
each model, the policyholders are ranked from safest to riskiest based on the
model predictions and the fraction of observed total cumulated claims is
plotted on the y axis. This plot is often called the ordered Lorenz curve of
the model.</p>
<p>The Gini coefficient (based on the area between the curve and the diagonal)
can be used as a model selection metric to quantify the ability of the model
to rank policyholders. Note that this metric does not reflect the ability of
the models to make accurate predictions in terms of absolute value of total
claim amounts but only in terms of relative amounts as a ranking metric. The
Gini coefficient is upper bounded by 1.0 but even an oracle model that ranks
the policyholders by the observed claim amounts cannot reach a score of 1.0.</p>
<p>We observe that both models are able to rank policyholders by risky-ness
significantly better than chance although they are also both far from the
oracle model due to the natural difficulty of the prediction problem from a
few features: most accidents are not predictable and can be caused by
environmental circumstances that are not described at all by the input
features of the models.</p>
<p>Note that the Gini index only characterizes the ranking performance of the
model but not its calibration: any monotonic transformation of the predictions
leaves the Gini index of the model unchanged.</p>
<p>Finally one should highlight that the Compound Poisson Gamma model that is
directly fit on the pure premium is operationally simpler to develop and
maintain as it consists of a single scikit-learn estimator instead of a pair
of models, each with its own set of hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">auc</span>


<span class="k">def</span> <span class="nf">lorenz_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">exposure</span><span class="p">):</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">exposure</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">exposure</span><span class="p">)</span>

    <span class="c1"># order samples by increasing predicted risk:</span>
    <span class="n">ranking</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">ranked_exposure</span> <span class="o">=</span> <span class="n">exposure</span><span class="p">[</span><span class="n">ranking</span><span class="p">]</span>
    <span class="n">ranked_pure_premium</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">ranking</span><span class="p">]</span>
    <span class="n">cumulated_claim_amount</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ranked_pure_premium</span> <span class="o">*</span> <span class="n">ranked_exposure</span><span class="p">)</span>
    <span class="n">cumulated_claim_amount</span> <span class="o">/=</span> <span class="n">cumulated_claim_amount</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">cumulated_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cumulated_claim_amount</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">cumulated_samples</span><span class="p">,</span> <span class="n">cumulated_claim_amount</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">y_pred_product</span> <span class="o">=</span> <span class="n">glm_freq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">*</span> <span class="n">glm_sev</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred_total</span> <span class="o">=</span> <span class="n">glm_pure_premium</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;Frequency * Severity model&quot;</span><span class="p">,</span> <span class="n">y_pred_product</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Compound Poisson Gamma&quot;</span><span class="p">,</span> <span class="n">y_pred_total</span><span class="p">),</span>
<span class="p">]:</span>
    <span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span> <span class="o">=</span> <span class="n">lorenz_curve</span><span class="p">(</span>
        <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">gini</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">auc</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">+=</span> <span class="s2">&quot; (Gini index: </span><span class="si">{:.3f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gini</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Oracle model: y_pred == y_test</span>
<span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span> <span class="o">=</span> <span class="n">lorenz_curve</span><span class="p">(</span>
    <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;PurePremium&quot;</span><span class="p">],</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;Exposure&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">gini</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">auc</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Oracle (Gini index: </span><span class="si">{:.3f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gini</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ordered_samples</span><span class="p">,</span> <span class="n">cum_claims</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-.&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Random baseline</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random baseline&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Lorenz Curves&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Fraction of policyholders</span><span class="se">\n</span><span class="s2">(ordered by model from safest to riskiest)&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Fraction of total claim amount&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[]
</pre></div>
</div>
<img alt="../../../../_images/3bde5696ae528f7cf5a509750dd70184f5ef155bd5194e00a48552dfe98afac5.png" src="../../../../_images/3bde5696ae528f7cf5a509750dd70184f5ef155bd5194e00a48552dfe98afac5.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./contents\regression\tutorials\lecture5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="examples.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Lecture 5: Examples of GLM and GAM</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="../../../machine-learning/logistic.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Logistical regression and classification</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>Lecture 5: Excercise</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#tweedie-regression-on-insurance-claims">Tweedie regression on insurance claims</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-datasets-basic-feature-extraction-and-target-definitions">Loading datasets, basic feature extraction and target definitions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frequency-model-poisson-distribution">Frequency model – Poisson distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#severity-model-gamma-distribution">Severity Model -  Gamma distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor">Pure Premium Modeling via a Product Model vs single TweedieRegressor</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Wengang Mao
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023-2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>